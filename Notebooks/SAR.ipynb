{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:27.613184Z",
     "start_time": "2024-05-15T18:14:23.127699Z"
    }
   },
   "source": [
    "import torch\n",
    "import pickle\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from config import ROOT_DIR\n",
    "import pandas as pd\n",
    "from libpysal.weights import Queen, Rook, DistanceBand, lat2W, WSP\n",
    "from pysal.model import spreg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import block_diag, csr_matrix\n",
    "import pysal.lib as lib\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"/Users/kevindesilva/ESC403_Project\")\n",
    "print(sys.path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/kevindesilva/ESC403_Project/Notebooks', '/Users/kevindesilva/ESC403_Project', '/Users/kevindesilva/anaconda3/lib/python311.zip', '/Users/kevindesilva/anaconda3/lib/python3.11', '/Users/kevindesilva/anaconda3/lib/python3.11/lib-dynload', '', '/Users/kevindesilva/anaconda3/lib/python3.11/site-packages', '/Users/kevindesilva/anaconda3/lib/python3.11/site-packages/aeosa', '/opt/gurobi201/linux32/lib/python2.5', '/Users/kevindesilva/ESC403_Project']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:28.464365Z",
     "start_time": "2024-05-15T18:14:28.428668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing = True\n",
    "read_path = r\"Data/trial/\" if testing else r\"Data/feature_engineered/\"\n",
    "\n",
    "X = load(ROOT_DIR / Path(read_path, \"X_fe.pkl\"))\n",
    "y = load(ROOT_DIR / Path(read_path, \"y_fe.pkl\"))"
   ],
   "id": "75de6c2b2b54cd3f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:31.043823Z",
     "start_time": "2024-05-15T18:14:31.040325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(X), X.shape)\n",
    "print(type(y), y.shape)"
   ],
   "id": "40b25640403e7343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([100, 64, 64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([100, 64, 64, 1])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#1: Elevation\n",
    "#2: Wind direction\n",
    "#3: Wind velocity\n",
    "#4: Min temp\n",
    "#5: Max temp\n",
    "#6: Humidity\n",
    "#7: Precip\n",
    "#8: Drought\n",
    "#9: Vegetation\n",
    "#10: Population density\n",
    "#11: Energy release component\n",
    "#12: Previous fire mask\n",
    "#13: Distance to Fire\n",
    "#14: Flow Accumulation\n",
    "#15: Fire Direction\n",
    "\n",
    "\n",
    "#Y 1: Next Day Fire Mask\n"
   ],
   "id": "2f1c1b80bb8ebe08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:33.155266Z",
     "start_time": "2024-05-15T18:14:33.152382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_np = X.numpy()\n",
    "y_np = y.numpy()\n"
   ],
   "id": "c6063fc7f07df362",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:35.176974Z",
     "start_time": "2024-05-15T18:14:35.118005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train-Test split\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X_np, y_np, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train_np)\n",
    "X_test = torch.tensor(X_test_np)\n",
    "y_train = torch.tensor(y_train_np)\n",
    "y_test = torch.tensor(y_test_np)\n",
    "\n",
    "print(\"Trainingsdaten Formen:\", X_train.shape, y_train.shape)\n",
    "print(\"Testdaten Formen:\", X_test.shape, y_test.shape)"
   ],
   "id": "c04bec893c6bfc40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten Formen: torch.Size([80, 64, 64, 15]) torch.Size([80, 64, 64, 1])\n",
      "Testdaten Formen: torch.Size([20, 64, 64, 15]) torch.Size([20, 64, 64, 1])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:36.045367Z",
     "start_time": "2024-05-15T18:14:36.041533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(X_train_np), X_train_np.shape)\n",
    "print(type(y_train_np), y_train_np.shape)"
   ],
   "id": "66d94c8206cd9aeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (80, 64, 64, 15)\n",
      "<class 'numpy.ndarray'> (80, 64, 64, 1)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T18:14:40.142719Z",
     "start_time": "2024-05-15T18:14:38.266968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Um das SAR Modell anzuwenden müssen die Daten 2D sein\n",
    "\n",
    "# Um SAR-Modelle anzuwenden, reshapen wir die Daten so, dass das Raster (64x64) beibehalten wird\n",
    "n_samples, height, width, n_features = X_train_np.shape\n",
    "\n",
    "# Reshape der Eingabedaten (X) und der Zielvariablen (y)\n",
    "X_train_reshaped = X_train_np.reshape(n_samples * height * width, n_features)\n",
    "y_train_reshaped = y_train_np.reshape(n_samples * height * width, 1)\n",
    "\n",
    "\n",
    "# Erzeuge die Gewichtsmatrix für das gesamte Dataset\n",
    "# Da wir hier mit 80 64x64-Rastern arbeiten, müssen wir eine Gewichtsmatrix für das gesamte Dataset erstellen\n",
    "# Das bedeutet, dass wir eine blockdiagonale Matrix erstellen müssen, die 80-mal die 64x64-Matrix enthält\n",
    "\n",
    "\n",
    "# Erzeuge eine Gewichtsmatrix für ein einzelnes 64x64-Raster\n",
    "w_single = lib.weights.lat2W(height, width)\n",
    "\n",
    "w_blocks = block_diag([w_single.sparse for _ in range(n_samples)], format='csr')\n",
    "\n",
    "# Konvertiere die blockdiagonale Matrix in ein PySAL W-Objekt\n",
    "# Wir müssen die Matrix manuell in das richtige Format konvertieren\n",
    "neighbors = {}\n",
    "weights = {}\n",
    "for i in range(n_samples):\n",
    "    for key, vals in w_single.neighbors.items():\n",
    "        new_key = key + i * height * width\n",
    "        new_vals = [val + i * height * width for val in vals]\n",
    "        neighbors[new_key] = new_vals\n",
    "        weights[new_key] = w_single.weights[key]\n",
    "\n",
    "w = lib.weights.W(neighbors, weights)\n",
    "\n",
    "w.transform = 'r'"
   ],
   "id": "51813c8be493a281",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/b1d1yp6d79z33w_6jvk6wcr80000gn/T/ipykernel_80211/1079147782.py:32: UserWarning: The weights matrix is not fully connected: \n",
      " There are 80 disconnected components.\n",
      "  w = lib.weights.W(neighbors, weights)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-15T18:15:10.902869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "def train_model(y_train, X_train, w, n_epochs):\n",
    "    # Initialize the progress bar with the total number of epochs\n",
    "    progress_bar = tqdm(total=n_epochs)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Simulate the training step (this would be your actual training code)\n",
    "        sar_model = spreg.ML_Lag(y_train, X_train, w=w, name_y='y', name_x=['X' + str(i) for i in range(X_train.shape[1])])\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    # Close the progress bar after training is complete\n",
    "    progress_bar.close()\n",
    "\n",
    "# Assuming y_train_reshaped and X_train_reshaped are your training data and w is your weights\n",
    "n_epochs = 100  # Total number of training epochs\n",
    "train_model(y_train_reshaped, X_train_reshaped, w, n_epochs)\n",
    "\n",
    "\n",
    "#sar_model = spreg.ML_Lag(y_train_reshaped, X_train_reshaped, w=w, name_y='y', name_x=['X' + str(i) for i in range(n_features)])\n",
    "\n",
    "# Modell-Details anzeigen\n",
    "\n",
    "#print(sar_model.summary)"
   ],
   "id": "4f247b5320a0d25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:31:14.988343Z",
     "start_time": "2024-05-15T17:31:14.976431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(X_train_reshaped), X_train_reshaped.shape)\n",
    "print(type(y_train_reshaped), y_train_reshaped.shape)\n",
    "\n",
    "print(type(w))"
   ],
   "id": "e134654c44b2c137",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (327680, 15)\n",
      "<class 'numpy.ndarray'> (327680, 1)\n",
      "<class 'libpysal.weights.weights.W'>\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
