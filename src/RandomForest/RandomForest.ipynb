{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "In this code the idea is to train a Random Forest to be able to predict the fire at the day t + 1. The main objective of this model is to evaluate if our 3 addictional predictors (Distance, Wind Propagation, Wind Direction) can bring added value to the prediction.\n",
    "\n",
    "Because at the end the goal is mostly to evaluate the predictors, we selected a subsample of 2000 events for the train set and 1000 for the test set, which correspond to ca. 8 million pixels and 4 million pixels respectively. This choice is to save time due to the computational burden (which is still a lot), while mainting quite a lot of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Total samples to select\n",
    "total_samples = 3000\n",
    "train_samples = 2000\n",
    "test_samples = 1000\n",
    "\n",
    "# Paths to your data files\n",
    "data_folder = os.path.join('..', '..', 'Data', 'feature_engineered')\n",
    "file_path1 = os.path.join(data_folder, 'X_fe.pkl')\n",
    "file_path2 = os.path.join(data_folder, 'y_fe.pkl')\n",
    "\n",
    "# Load the data\n",
    "with open(file_path1, 'rb') as f:\n",
    "    X_total = pickle.load(f)\n",
    "with open(file_path2, 'rb') as f:\n",
    "    y_total = pickle.load(f)\n",
    "\n",
    "# Generate random indices for selection\n",
    "indices = torch.randperm(len(X_total))[:total_samples]\n",
    "\n",
    "# Split indices into training and testing\n",
    "train_indices = indices[:train_samples]\n",
    "test_indices = indices[train_samples:train_samples + test_samples]\n",
    "\n",
    "# Select the samples for training and testing\n",
    "X_fe_train = X_total[train_indices]\n",
    "y_fe_train = y_total[train_indices]\n",
    "X_fe_test = X_total[test_indices]\n",
    "y_fe_test = y_total[test_indices]\n",
    "\n",
    "# Saving the training data\n",
    "train_X_path = os.path.join(data_folder, 'X_fe_train.pkl')\n",
    "train_y_path = os.path.join(data_folder, 'y_fe_train.pkl')\n",
    "with open(train_X_path, 'wb') as f:\n",
    "    pickle.dump(X_fe_train, f)\n",
    "with open(train_y_path, 'wb') as f:\n",
    "    pickle.dump(y_fe_train, f)\n",
    "\n",
    "# Saving the testing data\n",
    "test_X_path = os.path.join(data_folder, 'X_fe_test.pkl')\n",
    "test_y_path = os.path.join(data_folder, 'y_fe_test.pkl')\n",
    "with open(test_X_path, 'wb') as f:\n",
    "    pickle.dump(X_fe_test, f)\n",
    "with open(test_y_path, 'wb') as f:\n",
    "    pickle.dump(y_fe_test, f)\n",
    "\n",
    "print(\"Training and testing samples stored.\")\n",
    "print(\"Shape of X_fe_train:\", X_fe_train.shape)\n",
    "print(\"Shape of y_fe_train:\", y_fe_train.shape)\n",
    "print(\"Shape of X_fe_test:\", X_fe_test.shape)\n",
    "print(\"Shape of y_fe_test:\", y_fe_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second chunk we iterate trhrough the train sets (X and y) and we join them into a dataframe to be able to work with them and training a random forest. In this model we treat the entries pixelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192000, 16)\n",
      "   feature_1   feature_2  feature_3   feature_4   feature_5  feature_6  \\\n",
      "0       17.0  129.941940   2.038104  280.487183  297.019867   0.005786   \n",
      "1       17.0  128.303619   2.032815  280.436432  297.027832   0.005780   \n",
      "2       19.0  126.687485   2.026618  280.386139  297.035767   0.005774   \n",
      "3       19.0  125.100204   2.019579  280.336823  297.043671   0.005769   \n",
      "4       18.0  123.548439   2.011763  280.289032  297.051514   0.005763   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
      "0        0.0  -3.911050     2710.0    0.013650   58.152332         0.0   \n",
      "1        0.0  -3.968453     4229.0    0.198864   58.035343         0.0   \n",
      "2        0.0  -4.011178     2936.0    0.198864   57.921967         0.0   \n",
      "3        0.0  -4.041745     2936.0    0.198864   57.812614         0.0   \n",
      "4        0.0  -4.067156     3585.0    3.577682   57.707703         0.0   \n",
      "\n",
      "   feature_13  feature_14  feature_15  target  \n",
      "0   40.199501         0.0         0.0     0.0  \n",
      "1   39.204590         0.0         0.0     0.0  \n",
      "2   38.209946         0.0         0.0     0.0  \n",
      "3   37.215588         0.0         0.0     0.0  \n",
      "4   36.221542         0.0         0.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "pixel_data_list = []\n",
    "\n",
    "# Iterate over the samples of X_fe_train and y_fe_train\n",
    "for sample_idx in range(X_fe_train.shape[0]):\n",
    "    # Retrieve the feature tensor for the current sample\n",
    "    features_tensor = X_fe_train[sample_idx]\n",
    "    \n",
    "    # Retrieve the target tensor (y) for the current sample\n",
    "    target_tensor = y_fe_train[sample_idx]\n",
    "    \n",
    "    # For each pixel in the feature tensor\n",
    "    for row in range(features_tensor.shape[0]):\n",
    "        for col in range(features_tensor.shape[1]):\n",
    "            # Create a dictionary to represent the current pixel\n",
    "            pixel_data = {}\n",
    "            # Add the feature values as columns in the DataFrame\n",
    "            for feature_idx in range(features_tensor.shape[2]):\n",
    "                # Assign the current attribute's value to the pixel\n",
    "                pixel_data[f'feature_{feature_idx+1}'] = features_tensor[row, col, feature_idx].item()\n",
    "            \n",
    "            # Add the pixel's target attribute from the y tensor to the dictionary\n",
    "            pixel_data['target'] = target_tensor[row, col].item()\n",
    "            \n",
    "            # Append the dictionary to our list of pixel data\n",
    "            pixel_data_list.append(pixel_data)\n",
    "\n",
    "# Create a DataFrame using the list of pixel data\n",
    "pixel_df = pd.DataFrame(pixel_data_list)\n",
    "\n",
    "# Optionally print the shape or head of the DataFrame to check\n",
    "print(pixel_df.shape)\n",
    "print(pixel_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The further datapreprocessing is to assign the correct name to the features, which is indispensable to try different configuration and have in mind what kind of information each variable represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'feature_1': 'Elevation',\n",
    "    'feature_3': 'Wind_speed',\n",
    "    'feature_4': 'Min_temp',\n",
    "    'feature_5': 'Max_temp',\n",
    "    'feature_6': 'Humidity',\n",
    "    'feature_7': 'Precipitation',\n",
    "    'feature_8': 'Drought',\n",
    "    'feature_9': 'Vegetation',\n",
    "    'feature_10': 'Population_density',\n",
    "    'feature_11': 'Energy_release',\n",
    "    'feature_12': 'Mask',\n",
    "    'feature_13': 'Distance',\n",
    "    'feature_14': 'Wind_Propagation',\n",
    "    'feature_15': 'Wind_trajectory'\n",
    "}\n",
    "\n",
    "pixel_df.drop(columns=['feature_2'], inplace=True)\n",
    "\n",
    "pixel_df.rename(columns=new_column_names, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we first eliminate the entries of the fire mask at day t which as value of -1.0. This represents pixel for wich the cloud cover introduces uncertainty on the measurment of the variables via remote sensing. We belive these pixels could  to bias in our results. Then because the random forest need. We tried different configuration, and augmenting the number of pixels with no fire led to a better precision but a worse recall. We tried to identify a good configuration by evaluating the F1 score. This led to a ratio of 1:20 of fire:non-fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Min_temp</th>\n",
       "      <th>Max_temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Drought</th>\n",
       "      <th>Vegetation</th>\n",
       "      <th>Population_density</th>\n",
       "      <th>Energy_release</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Wind_Propagation</th>\n",
       "      <th>Wind_trajectory</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.480936</td>\n",
       "      <td>280.038361</td>\n",
       "      <td>297.215057</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.579317</td>\n",
       "      <td>4533.0</td>\n",
       "      <td>15.112425</td>\n",
       "      <td>59.165180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.478768</td>\n",
       "      <td>280.086426</td>\n",
       "      <td>297.212616</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.607681</td>\n",
       "      <td>4533.0</td>\n",
       "      <td>18.809578</td>\n",
       "      <td>59.384743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.492248</td>\n",
       "      <td>279.875580</td>\n",
       "      <td>297.238068</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.512801</td>\n",
       "      <td>6034.0</td>\n",
       "      <td>1.781425</td>\n",
       "      <td>58.481659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.487910</td>\n",
       "      <td>279.917725</td>\n",
       "      <td>297.235229</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.543429</td>\n",
       "      <td>7152.0</td>\n",
       "      <td>31.809210</td>\n",
       "      <td>58.692970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.484172</td>\n",
       "      <td>279.961945</td>\n",
       "      <td>297.232391</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.583336</td>\n",
       "      <td>7152.0</td>\n",
       "      <td>12.194407</td>\n",
       "      <td>58.909325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470059</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556826</th>\n",
       "      <td>1248.0</td>\n",
       "      <td>1.595683</td>\n",
       "      <td>279.274811</td>\n",
       "      <td>292.631989</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.035736</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>0.115359</td>\n",
       "      <td>44.555119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366067</th>\n",
       "      <td>2054.0</td>\n",
       "      <td>2.694889</td>\n",
       "      <td>285.571838</td>\n",
       "      <td>301.987213</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976659</td>\n",
       "      <td>6068.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.533661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.440307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488256</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.215159</td>\n",
       "      <td>285.878754</td>\n",
       "      <td>299.545258</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.447216</td>\n",
       "      <td>-1.451233</td>\n",
       "      <td>6178.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.355818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.552946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941089</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>4.187360</td>\n",
       "      <td>283.912537</td>\n",
       "      <td>303.558411</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-2.272292</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.826225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.464249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496125</th>\n",
       "      <td>2245.0</td>\n",
       "      <td>4.549484</td>\n",
       "      <td>280.835327</td>\n",
       "      <td>301.496002</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.080257</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.870926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.246211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984332 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Elevation  Wind_speed    Min_temp    Max_temp  Humidity  \\\n",
       "171           25.0    1.480936  280.038361  297.215057  0.005682   \n",
       "172           25.0    1.478768  280.086426  297.212616  0.005682   \n",
       "231           25.0    1.492248  279.875580  297.238068  0.005677   \n",
       "232           25.0    1.487910  279.917725  297.235229  0.005677   \n",
       "233           25.0    1.484172  279.961945  297.232391  0.005677   \n",
       "...            ...         ...         ...         ...       ...   \n",
       "5556826     1248.0    1.595683  279.274811  292.631989  0.003968   \n",
       "1366067     2054.0    2.694889  285.571838  301.987213  0.006001   \n",
       "2488256        5.0    2.215159  285.878754  299.545258  0.010306   \n",
       "2941089     1533.0    4.187360  283.912537  303.558411  0.004720   \n",
       "3496125     2245.0    4.549484  280.835327  301.496002  0.001869   \n",
       "\n",
       "         Precipitation   Drought  Vegetation  Population_density  \\\n",
       "171           0.000000 -2.579317      4533.0           15.112425   \n",
       "172           0.000000 -2.607681      4533.0           18.809578   \n",
       "231           0.000000 -2.512801      6034.0            1.781425   \n",
       "232           0.000000 -2.543429      7152.0           31.809210   \n",
       "233           0.000000 -2.583336      7152.0           12.194407   \n",
       "...                ...       ...         ...                 ...   \n",
       "5556826       0.000000 -1.035736      2694.0            0.115359   \n",
       "1366067       0.000000  0.976659      6068.0            0.000000   \n",
       "2488256       0.447216 -1.451233      6178.0            0.000000   \n",
       "2941089       0.000045 -2.272292      2077.0            0.000000   \n",
       "3496125       0.000000 -3.080257      3872.0            0.000000   \n",
       "\n",
       "         Energy_release  Mask   Distance  Wind_Propagation  Wind_trajectory  \\\n",
       "171           59.165180   0.0   2.828427               0.0         0.682421   \n",
       "172           59.384743   0.0   3.605551               0.0         0.734017   \n",
       "231           58.481659   0.0   1.414214               0.0         0.190179   \n",
       "232           58.692970   0.0   1.000000               0.0         0.246162   \n",
       "233           58.909325   0.0   1.000000               0.0         0.470059   \n",
       "...                 ...   ...        ...               ...              ...   \n",
       "5556826       44.555119   0.0   5.000000               0.0         0.958098   \n",
       "1366067       80.533661   0.0  10.440307               0.0         0.000000   \n",
       "2488256       21.355818   0.0  16.552946               0.0         0.999860   \n",
       "2941089       83.826225   0.0  17.464249               0.0         0.761425   \n",
       "3496125      108.870926   0.0   8.246211               0.0         0.000000   \n",
       "\n",
       "         target  \n",
       "171         1.0  \n",
       "172         1.0  \n",
       "231         1.0  \n",
       "232         1.0  \n",
       "233         1.0  \n",
       "...         ...  \n",
       "5556826     0.0  \n",
       "1366067     0.0  \n",
       "2488256     0.0  \n",
       "2941089     0.0  \n",
       "3496125     0.0  \n",
       "\n",
       "[1984332 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where 'Mask' or 'target' values are -1.000000\n",
    "rows_to_drop = pixel_df[(pixel_df['Mask'] == -1.000000) | (pixel_df['target'] == -1.000)].index\n",
    "pixel_df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Round the number of rows with 'target' equal to 1 to the nearest integer\n",
    "num_target_1 = int(pixel_df['target'].sum())\n",
    "\n",
    "# Randomly select rows where 'target' has a value of 0\n",
    "# so that the total number of rows with 'target' equal to 0 is equal to the number of rows with 'target' equal to 1\n",
    "rows_target_0 = pixel_df[pixel_df['target'] == 0].index\n",
    "rows_to_keep_target_0 = np.random.choice(rows_target_0, size=num_target_1*20, replace=False)\n",
    "\n",
    "# Create a new balanced DataFrame using the selected rows\n",
    "balanced_df = pixel_df.loc[pixel_df['target'] == 1].copy()\n",
    "balanced_df = pd.concat([balanced_df, pixel_df.loc[rows_to_keep_target_0]])\n",
    "\n",
    "balanced_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chunk we tried to find the better configuration of some hyperparameters with only using the 2000 samples and splitting them 80/20. The best model was saved and then the best hyperparameters were used to try different configurations of the different variables. The best hyperparameters were selected according to a 10 fold cross validation evaluating the best accuracy on the train set. We couldn't try a lot of parameters because it was very computational intensive, but at least we tried 256 different configurations (4x4 hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[7448   45]\n",
      " [  91  458]]\n",
      "Accuracy sul set di test: 0.9830887838846059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = balanced_df.drop(columns=['target'])\n",
    "y = balanced_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [2, 4, 8, 10],\n",
    "}\n",
    "\n",
    "# Perform the search for the best hyperparameters using cross-validation\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Train the best model on the training set\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on the test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saved our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "data_folder = os.path.join('..', '..', 'Data', 'rf_models')\n",
    "file_path = os.path.join(data_folder, 'rf_complete.pkl')\n",
    "\n",
    "joblib.dump(best_rf, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we trained the random forest with the best hyperparameter on the balanced dataset with all the 3 new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split features and targets\n",
    "X = balanced_df.drop(columns=['target'])\n",
    "y = balanced_df['target']\n",
    "\n",
    "# Load the best model's hyperparameters\n",
    "data_folder = os.path.join('..', '..', 'Data', 'rf_models')\n",
    "model_path = os.path.join(data_folder, 'rf_complete.pkl')\n",
    "best_rf = joblib.load(model_path)\n",
    "\n",
    "# Create a new RandomForest model using the best model's parameters\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=best_rf.n_estimators,\n",
    "    max_depth=best_rf.max_depth,\n",
    "    min_samples_split=best_rf.min_samples_split,\n",
    "    min_samples_leaf=best_rf.min_samples_leaf,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model with the entire balanced dataset\n",
    "rf_final.fit(X, y)\n",
    "\n",
    "# Save the fully trained model\n",
    "final_model_path = os.path.join(data_folder, 'rf_final.pkl')\n",
    "joblib.dump(rf_final, final_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for the test set we also converted the matrices into pixels for the test set in the same way we did before to execute the evaluation of the models on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096000, 16)\n",
      "   feature_1  feature_2  feature_3   feature_4   feature_5  feature_6  \\\n",
      "0      464.0  64.707497   3.021777  279.242523  294.727509   0.005980   \n",
      "1      462.0  64.624336   3.023418  279.241394  294.738037   0.005987   \n",
      "2      460.0  64.496925   3.025670  279.239563  294.748505   0.005995   \n",
      "3      460.0  64.330299   3.028472  279.237122  294.758942   0.006003   \n",
      "4      457.0  64.129494   3.031759  279.234161  294.769379   0.006010   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
      "0        0.0  -2.577915     3231.0    0.701497   27.608435         0.0   \n",
      "1        0.0  -2.571581     3830.0    2.079772   27.567842         0.0   \n",
      "2        0.0  -2.562931     4416.0    0.348947   27.530993         0.0   \n",
      "3        0.0  -2.550874     4043.0    0.348947   27.497467         0.0   \n",
      "4        0.0  -2.533433     4043.0    0.981675   27.466850         0.0   \n",
      "\n",
      "   feature_13  feature_14  feature_15  target  \n",
      "0   41.773197         0.0         0.0    -1.0  \n",
      "1   40.792156         0.0         0.0    -1.0  \n",
      "2   39.812057         0.0         0.0    -1.0  \n",
      "3   38.832977         0.0         0.0    -1.0  \n",
      "4   37.854988         0.0         0.0    -1.0  \n"
     ]
    }
   ],
   "source": [
    "pixel_data_list_test = []\n",
    "\n",
    "# Iterate over the samples of X_fe_test and y_fe_test\n",
    "for sample_idx in range(X_fe_test.shape[0]):\n",
    "    # Retrieve the feature tensor for the current sample\n",
    "    features_tensor = X_fe_test[sample_idx]\n",
    "    \n",
    "    # Retrieve the target tensor (y) for the current sample\n",
    "    target_tensor = y_fe_test[sample_idx]\n",
    "    \n",
    "    # For each pixel in the feature tensor\n",
    "    for row in range(features_tensor.shape[0]):\n",
    "        for col in range(features_tensor.shape[1]):\n",
    "            # Create a dictionary to represent the current pixel\n",
    "            pixel_data_test = {}\n",
    "            \n",
    "            # Add the feature values as columns in the DataFrame\n",
    "            for feature_idx in range(features_tensor.shape[2]):\n",
    "                # Assign the current attribute's value to the pixel\n",
    "                pixel_data_test[f'feature_{feature_idx+1}'] = features_tensor[row, col, feature_idx].item()\n",
    "            \n",
    "            # Add the pixel's target attribute from the y tensor to the dictionary\n",
    "            pixel_data_test['target'] = target_tensor[row, col].item()\n",
    "            \n",
    "            # Append the dictionary to our list of pixel data\n",
    "            pixel_data_list_test.append(pixel_data_test)\n",
    "\n",
    "# Create a DataFrame using the list of pixel data\n",
    "pixel_df_test = pd.DataFrame(pixel_data_list_test)\n",
    "\n",
    "# Optionally print the shape or head of the DataFrame to check\n",
    "print(pixel_df_test.shape)\n",
    "print(pixel_df_test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain consistency we also did the same preprocessing for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096000, 15)\n",
      "   Elevation  Wind_speed    Min_temp    Max_temp  Humidity  Precipitation  \\\n",
      "0      464.0    3.021777  279.242523  294.727509  0.005980            0.0   \n",
      "1      462.0    3.023418  279.241394  294.738037  0.005987            0.0   \n",
      "2      460.0    3.025670  279.239563  294.748505  0.005995            0.0   \n",
      "3      460.0    3.028472  279.237122  294.758942  0.006003            0.0   \n",
      "4      457.0    3.031759  279.234161  294.769379  0.006010            0.0   \n",
      "\n",
      "    Drought  Vegetation  Population_density  Energy_release  Mask   Distance  \\\n",
      "0 -2.577915      3231.0            0.701497       27.608435   0.0  41.773197   \n",
      "1 -2.571581      3830.0            2.079772       27.567842   0.0  40.792156   \n",
      "2 -2.562931      4416.0            0.348947       27.530993   0.0  39.812057   \n",
      "3 -2.550874      4043.0            0.348947       27.497467   0.0  38.832977   \n",
      "4 -2.533433      4043.0            0.981675       27.466850   0.0  37.854988   \n",
      "\n",
      "   Wind_Propagation  Wind_trajectory  target  \n",
      "0               0.0              0.0    -1.0  \n",
      "1               0.0              0.0    -1.0  \n",
      "2               0.0              0.0    -1.0  \n",
      "3               0.0              0.0    -1.0  \n",
      "4               0.0              0.0    -1.0  \n"
     ]
    }
   ],
   "source": [
    "# Remove the 'feature_2' column from the test dataset\n",
    "pixel_df_test.drop(columns=['feature_2'], inplace=True)\n",
    "\n",
    "\n",
    "# Rename the columns using the new column names in the test dataset\n",
    "pixel_df_test.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Optionally print the shape or head of the DataFrame to check\n",
    "print(pixel_df_test.shape)\n",
    "print(pixel_df_test.head())\n",
    "\n",
    "rows_to_drop_test = pixel_df_test[(pixel_df_test['Mask'] == -1.000000) | (pixel_df_test['target'] == -1.000)].index\n",
    "pixel_df_test.drop(rows_to_drop_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the evaluation of the performance of the Random Forest with all the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3899907   25191]\n",
      " [  21326   25536]]\n",
      "Accuracy: 0.9882886534607599\n",
      "Precision: 0.5034005559169673\n",
      "Recall: 0.5449191242371217\n",
      "F1 Score: 0.5233376712539323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "#pixel_df_test.drop(columns=['predicted'], inplace=True)\n",
    "\n",
    "model_path = os.path.join('..', '..', 'Data', 'rf_models', 'rf_final.pkl')\n",
    "\n",
    "rf_final = joblib.load(model_path)\n",
    "\n",
    "# Assuming pixel_df_test is already preprocessed and ready for prediction\n",
    "X_test = pixel_df_test.drop(columns=['target'])  # Extract features for prediction\n",
    "y_test = pixel_df_test['target']  # Actual labels\n",
    "\n",
    "# Make predictions\n",
    "predicted = rf_final.predict(X_test)\n",
    "\n",
    "# Add predictions to pixel_df_test\n",
    "pixel_df_test['predicted'] = predicted\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(y_test, predicted)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "precision = precision_score(y_test, predicted)\n",
    "recall = recall_score(y_test, predicted)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try the same model Random Forest on the same training set with the same hyperparameters without the addictional variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume balanced_df is already loaded and ready\n",
    "balanced_df_base = balanced_df.drop(columns=['Distance', 'Wind_Propagation', 'Wind_trajectory'])\n",
    "\n",
    "X_base = balanced_df_base.drop(columns=['target'])\n",
    "y_base = balanced_df_base['target']\n",
    "\n",
    "data_folder = os.path.join('..', '..', 'Data', 'rf_models')\n",
    "model_path = os.path.join(data_folder, 'rf_complete.pkl')\n",
    "best_rf = joblib.load(model_path)\n",
    "\n",
    "# Create a new RandomForest model using the loaded parameters\n",
    "rf_final_base = RandomForestClassifier(\n",
    "    n_estimators=best_rf.n_estimators,\n",
    "    max_depth=best_rf.max_depth,\n",
    "    min_samples_split=best_rf.min_samples_split,\n",
    "    min_samples_leaf=best_rf.min_samples_leaf,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the new model with the modified dataset\n",
    "rf_final_base.fit(X_base, y_base)\n",
    "\n",
    "final_model_path_base = os.path.join(data_folder, 'rf_final_base.pkl')\n",
    "joblib.dump(rf_final_base, final_model_path_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we evaluated the performance of the model without the addictional predictors and realized that we obtained similar result. What we found out is that with all the predictors the model doesen't change and become even a litell bit worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for the base model:\n",
      "[[3910109   14989]\n",
      " [  23645   23217]]\n",
      "Accuracy for the base model: 0.9902733159447729\n",
      "Precision for the base model: 0.6076794220803016\n",
      "Recall for the base model: 0.4954334001963211\n",
      "F1 Score for the base model: 0.5458456764000564\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have X_test and y_test prepared from your earlier processing steps\n",
    "\n",
    "# Drop the specified columns from X_test to create X_test_base\n",
    "# (List columns to drop - the same ones you initially removed to train rf_final_base)\n",
    "columns_to_drop = ['Distance', 'Wind_Propagation', 'Wind_trajectory']\n",
    "X_test_base = X_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Load the rf_final_base model\n",
    "model_path_base = os.path.join('..', '..', 'Data', 'rf_models', 'rf_final_base.pkl')\n",
    "rf_final_base = joblib.load(model_path_base)\n",
    "\n",
    "# Make predictions using rf_final_base on X_test_base\n",
    "predicted_base = rf_final_base.predict(X_test_base)\n",
    "\n",
    "# The target labels remain the same so y_test_base is simply y_test\n",
    "y_test_base = y_test\n",
    "\n",
    "# Calculate metrics using predictions\n",
    "conf_matrix_base = confusion_matrix(y_test_base, predicted_base)\n",
    "accuracy_base = accuracy_score(y_test_base, predicted_base)\n",
    "precision_base = precision_score(y_test_base, predicted_base, average='binary')  # adjust average method if not binary\n",
    "recall_base = recall_score(y_test_base, predicted_base, average='binary')\n",
    "f1_base = f1_score(y_test_base, predicted_base, average='binary')\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix for the base model:\")\n",
    "print(conf_matrix_base)\n",
    "print(\"Accuracy for the base model:\", accuracy_base)\n",
    "print(\"Precision for the base model:\", precision_base)\n",
    "print(\"Recall for the base model:\", recall_base)\n",
    "print(\"F1 Score for the base model:\", f1_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not obtain the desired results, we tried to see if different configurations of variables would lead to better results. We did this with simpler model hyperparameters (like maximum depth minor) but just to get an idea, here we found that the best configuration is with just wind_trajectory and wind_speed (based on F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello: rf_distance\n",
      "Confusion Matrix:\n",
      "[[3904031   21067]\n",
      " [  34064   12798]]\n",
      "Accuracy: 0.9861199508554971\n",
      "Precision: 0.377912298833604\n",
      "Recall: 0.2730997396611327\n",
      "F1 Score: 0.31706863874540114\n",
      "----------\n",
      "\n",
      "Modello: rf_wind_propagation\n",
      "Confusion Matrix:\n",
      "[[3894924   30174]\n",
      " [  30718   16144]]\n",
      "Accuracy: 0.9846695334293397\n",
      "Precision: 0.34854700116585347\n",
      "Recall: 0.3445008749093082\n",
      "F1 Score: 0.34651212706589396\n",
      "----------\n",
      "\n",
      "Modello: rf_wind_trajectory\n",
      "Confusion Matrix:\n",
      "[[3894078   31020]\n",
      " [  30406   16456]]\n",
      "Accuracy: 0.9845350909878247\n",
      "Precision: 0.34661723818350326\n",
      "Recall: 0.35115872135205495\n",
      "F1 Score: 0.34887320061905064\n",
      "----------\n",
      "\n",
      "Modello: rf_distance_wind_propagation\n",
      "Confusion Matrix:\n",
      "[[3906505   18593]\n",
      " [  35115   11747]]\n",
      "Accuracy: 0.9864782122679987\n",
      "Precision: 0.38717864205669084\n",
      "Recall: 0.2506721864197004\n",
      "F1 Score: 0.3043185409704412\n",
      "----------\n",
      "\n",
      "Modello: rf_distance_wind_trajectory\n",
      "Confusion Matrix:\n",
      "[[3903089   22009]\n",
      " [  33709   13153]]\n",
      "Accuracy: 0.9859721648757792\n",
      "Precision: 0.37406859678061544\n",
      "Recall: 0.28067517391489905\n",
      "F1 Score: 0.32071101141129427\n",
      "----------\n",
      "\n",
      "Modello: rf_wind_propagation_wind_trajectory\n",
      "Confusion Matrix:\n",
      "[[3892890   32208]\n",
      " [  29914   16948]]\n",
      "Accuracy: 0.984359862637086\n",
      "Precision: 0.3447798844495077\n",
      "Recall: 0.3616576330502326\n",
      "F1 Score: 0.35301714261909223\n",
      "----------\n",
      "\n",
      "Modello: rf_distance_wind_propagation_wind_trajectory\n",
      "Confusion Matrix:\n",
      "[[3907262   17836]\n",
      " [  35138   11724]]\n",
      "Accuracy: 0.9866630076838638\n",
      "Precision: 0.396617050067659\n",
      "Recall: 0.250181383637062\n",
      "F1 Score: 0.30682264269451204\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Variables and combinations\n",
    "variables = ['Distance', 'Wind_Propagation', 'Wind_trajectory']\n",
    "combinations = list(itertools.combinations(variables, r) for r in range(1, len(variables) + 1))\n",
    "combinations = [item for sublist in combinations for item in sublist]  # Flatten the list\n",
    "\n",
    "# Assume balanced_df is already loaded and ready\n",
    "X = balanced_df.drop(columns=['target'])\n",
    "y = balanced_df['target']\n",
    "\n",
    "# Assume pixel_df_test is already prepared and ready for use\n",
    "X_test_full = pixel_df_test.drop(columns=['target'])\n",
    "y_test = pixel_df_test['target']\n",
    "\n",
    "# Model parameters (assuming they have been defined or loaded)\n",
    "n_estimators = 100  # Example, define according to your data\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1\n",
    "\n",
    "for combo in combinations:\n",
    "    model_name = 'rf_' + '_'.join(combo).lower()\n",
    "    columns_to_drop = list(combo)\n",
    "    X_train = X.drop(columns=columns_to_drop)\n",
    "    X_test = X_test_full.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='binary')\n",
    "    recall = recall_score(y_test, predictions, average='binary')\n",
    "    f1 = f1_score(y_test, predictions, average='binary')\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"----------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of what we found out before we tried a model with the same hyperparameters only without the variable Distance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the model's base parameters\n",
    "data_folder = os.path.join('..', '..', 'Data', 'rf_models')\n",
    "model_path = os.path.join(data_folder, 'rf_complete.pkl')\n",
    "best_rf = joblib.load(model_path)\n",
    "\n",
    "# Prepare the training dataset\n",
    "X_train_best = balanced_df.drop(columns=['target', 'Distance'])\n",
    "y_train_best = balanced_df['target']\n",
    "\n",
    "# Display loaded hyperparameters\n",
    "print(\"Loaded model hyperparameters:\")\n",
    "print(\"Number of estimators:\", best_rf.n_estimators)\n",
    "print(\"Maximum depth:\", best_rf.max_depth)\n",
    "print(\"Minimum samples split:\", best_rf.min_samples_split)\n",
    "print(\"Minimum samples leaf:\", best_rf.min_samples_leaf)\n",
    "\n",
    "# Train the RandomForest model with the loaded parameters\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=best_rf.n_estimators,\n",
    "    max_depth=best_rf.max_depth,\n",
    "    min_samples_split=best_rf.min_samples_split,\n",
    "    min_samples_leaf=best_rf.min_samples_leaf,\n",
    "    random_state=42\n",
    ")\n",
    "rf_best.fit(X_train_best, y_train_best)\n",
    "\n",
    "# Path to save the trained model\n",
    "final_model_path = os.path.join(data_folder, 'rf_best.pkl')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(rf_best, final_model_path)\n",
    "print(\"The model was successfully saved to:\", final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for the best model:\n",
      "[[3906530   18568]\n",
      " [  23550   23312]]\n",
      "Accuracy for the best model: 0.9893961671315925\n",
      "Precision for the best model: 0.5566380133715377\n",
      "Recall for the best model: 0.4974606290811318\n",
      "F1 Score for the best model: 0.5253882040071217\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the already trained model\n",
    "data_folder = os.path.join('..', '..', 'Data', 'rf_models')\n",
    "final_model_path = os.path.join(data_folder, 'rf_best.pkl')\n",
    "rf_best = joblib.load(final_model_path)\n",
    "\n",
    "# Assume that pixel_df_test is already defined and prepared as above\n",
    "# Check if 'Distance' is one of the columns and remove it if present\n",
    "if 'Distance' in pixel_df_test.columns:\n",
    "    X_test_best = pixel_df_test.drop(columns=['Distance'])\n",
    "else:\n",
    "    X_test_best = pixel_df_test.copy()\n",
    "\n",
    "# Separate the targets\n",
    "y_test_best = X_test_best.pop('target')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predicted_best = rf_best.predict(X_test_best)\n",
    "conf_matrix_best = confusion_matrix(y_test_best, predicted_best)\n",
    "accuracy_best = accuracy_score(y_test_best, predicted_best)\n",
    "precision_best = precision_score(y_test_best, predicted_best, average='binary')\n",
    "recall_best = recall_score(y_test_best, predicted_best, average='binary')\n",
    "f1_best = f1_score(y_test_best, predicted_best, average='binary')\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix for the best model:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Accuracy for the best model:\", accuracy_best)\n",
    "print(\"Precision for the best model:\", precision_best)\n",
    "print(\"Recall for the best model:\", recall_best)\n",
    "print(\"F1 Score for the best model:\", f1_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to visualize our results through 6 samples which are neither in the train nor in the test set. We selected some good, some bad, some with cloud a little bit to have an overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Specific indices of samples to select\n",
    "specific_indices = [952, 1511, 4351, 5995, 7376, 15344]\n",
    "\n",
    "# Extract specific samples\n",
    "X_random = X_total[specific_indices]\n",
    "y_random = y_total[specific_indices]\n",
    "\n",
    "\n",
    "# Prepare data for the DataFrame\n",
    "pixel_data_list_random = []\n",
    "for sample_idx in range(X_random.shape[0]):\n",
    "    features_tensor = X_random[sample_idx]\n",
    "    target_tensor = y_random[sample_idx]\n",
    "    for row in range(features_tensor.shape[0]):\n",
    "        for col in range(features_tensor.shape[1]):\n",
    "            pixel_data = {}\n",
    "            for feature_idx in range(features_tensor.shape[2]):\n",
    "                pixel_data[f'feature_{feature_idx+1}'] = features_tensor[row, col, feature_idx].item()\n",
    "            pixel_data['target'] = target_tensor[row, col].item()\n",
    "            pixel_data_list_random.append(pixel_data)\n",
    "\n",
    "# Convert to DataFrame and prepare for prediction\n",
    "pixel_df_random = pd.DataFrame(pixel_data_list_random)\n",
    "if 'feature_2' in pixel_df_random.columns:  # Assuming 'feature_2' is 'Distance'\n",
    "    pixel_df_random.drop(columns=['feature_2'], inplace=True)\n",
    "pixel_df_random.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Remove the target column for prediction\n",
    "X_random_prepared = pixel_df_random.drop(columns=['target'])\n",
    "y_random_actual = pixel_df_random['target']\n",
    "\n",
    "# Load the trained model\n",
    "rf_best = joblib.load(final_model_path)\n",
    "\n",
    "# Ensure the dataset for predictions does not contain the 'Distance' column\n",
    "if 'Distance' in X_random_prepared.columns:\n",
    "    X_random_prepared = X_random_prepared.drop(columns=['Distance'])\n",
    "\n",
    "# Make predictions on specific samples\n",
    "predicted_random = rf_best.predict(X_random_prepared)\n",
    "\n",
    "# Organize predictions into matrices for visualization\n",
    "predicted_matrices = []\n",
    "original_matrices = []\n",
    "for i in range(6):  # Now for 6 samples\n",
    "    start_idx = i * 64 * 64\n",
    "    end_idx = start_idx + 64 * 64\n",
    "    predicted_matrix = predicted_random[start_idx:end_idx].reshape(64, 64)\n",
    "    original_matrix = y_random[i].reshape(64, 64)\n",
    "    predicted_matrices.append(predicted_matrix)\n",
    "    original_matrices.append(original_matrix)\n",
    "\n",
    "# Plotting without legends\n",
    "fig, axes = plt.subplots(2, 6, figsize=(24, 8), gridspec_kw={'height_ratios': [1, 1]})  # Adjusted for 6 samples\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    cmap = plt.cm.coolwarm\n",
    "    if i < 6:  # Predicted matrices\n",
    "        ax.imshow(predicted_matrices[i], cmap=cmap)\n",
    "        ax.set_title(f'Predicted - Sample {specific_indices[i]}')\n",
    "    else:  # Original matrices\n",
    "        ax.imshow(original_matrices[i-6], cmap=cmap)\n",
    "        ax.set_title(f'Original - Sample {specific_indices[i-6]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
